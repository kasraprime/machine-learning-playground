{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Tracking with W&B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code is partly adopted from [wandb.me/intro](https://wandb.me/intro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import math, random\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchviz import make_dot\n",
    "import pickle\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"device in use is {device}\")\n",
    "\n",
    "def load_data(is_train, batch_size, subset=5):\n",
    "    \"Loading MNIST dataset\"\n",
    "    full_dataset = torchvision.datasets.MNIST(root=\".\", train=is_train, transform=T.ToTensor(), download=True)\n",
    "    sub_dataset = torch.utils.data.Subset(full_dataset, indices=range(0, len(full_dataset), subset))\n",
    "    loader = torch.utils.data.DataLoader(dataset=sub_dataset, batch_size=batch_size, shuffle=True if is_train else False, pin_memory=True, num_workers=4)\n",
    "    return loader\n",
    "\n",
    "def the_model(dropout):\n",
    "    model = nn.Sequential(nn.Flatten(), nn.Linear(28*28, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(dropout), nn.Linear(256,10)).to(device)\n",
    "    return model\n",
    "\n",
    "def validate_model(model, valid_dl, loss_func, log_images=False, batch_idx=0):\n",
    "    \"Compute performance of the model on the validation dataset and log a wandb.Table\"\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        for i, (images, labels) in enumerate(valid_dl):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            val_loss += loss_func(outputs, labels)*labels.size(0)\n",
    "\n",
    "            # Compute accuracy and accumulate\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Log one batch of images to the dashboard, always same batch_idx.\n",
    "            if i==batch_idx and log_images:\n",
    "                log_image_table(images, predicted, labels, outputs.softmax(dim=1))\n",
    "    return val_loss / len(valid_dl.dataset), correct / len(valid_dl.dataset)\n",
    "\n",
    "def log_image_table(images, predicted, labels, probs):\n",
    "    \"Log a wandb.Table with (img, pred, target, scores)\"\n",
    "    # Create a wandb Table to log images, labels and predictions\n",
    "    table = wandb.Table(columns=[\"image\", \"prediction\", \"target\"]+[f\"score_{i}\" for i in range(10)])\n",
    "    for img, pred, targ, prob in zip(images.to(\"cpu\"), predicted.to(\"cpu\"), labels.to(\"cpu\"), probs.to(\"cpu\")):\n",
    "        table.add_data(wandb.Image(img[0].numpy()*255), pred, targ, *prob.numpy())\n",
    "    wandb.log({\"predictions_table\":table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/p/work/kasra/machine-learning-playground/wandb/run-20221002_115622-mvrmqlmt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kasraprime/experiment-tracking/runs/mvrmqlmt\" target=\"_blank\">easy-planet-35</a></strong> to <a href=\"https://wandb.ai/kasraprime/experiment-tracking\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Train Loss: 0.379, Valid Loss: 0.284890, Accuracy: 0.91\n",
      "Epoch 1. Train Loss: 0.262, Valid Loss: 0.229349, Accuracy: 0.93\n",
      "Epoch 2. Train Loss: 0.130, Valid Loss: 0.194712, Accuracy: 0.94\n",
      "Epoch 3. Train Loss: 0.130, Valid Loss: 0.184114, Accuracy: 0.94\n",
      "Epoch 4. Train Loss: 0.096, Valid Loss: 0.181357, Accuracy: 0.94\n",
      "Epoch 5. Train Loss: 0.119, Valid Loss: 0.167953, Accuracy: 0.95\n",
      "Epoch 6. Train Loss: 0.105, Valid Loss: 0.158096, Accuracy: 0.95\n",
      "Epoch 7. Train Loss: 0.031, Valid Loss: 0.160057, Accuracy: 0.95\n",
      "Epoch 8. Train Loss: 0.064, Valid Loss: 0.158707, Accuracy: 0.95\n",
      "Epoch 9. Train Loss: 0.101, Valid Loss: 0.162270, Accuracy: 0.95\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116a5ca2cf034dc2897ba0a6842f9c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.869 MB of 1.681 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.517052…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/train_loss</td><td>█▅▄▄▂▂▃▂▂▂▂▂▁▂▂▂▂▂▂▁▁▁▁▂▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/val_accuracy</td><td>▁▃▆▆▆▇█▇██</td></tr><tr><td>val/val_loss</td><td>█▅▃▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>0</td></tr><tr><td>test_accuracy</td><td>0.8</td></tr><tr><td>train/epoch</td><td>9</td></tr><tr><td>train/train_loss</td><td>0.10094</td></tr><tr><td>val/val_accuracy</td><td>0.9535</td></tr><tr><td>val/val_loss</td><td>0.16227</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">easy-planet-35</strong>: <a href=\"https://wandb.ai/kasraprime/experiment-tracking/runs/mvrmqlmt\" target=\"_blank\">https://wandb.ai/kasraprime/experiment-tracking/runs/mvrmqlmt</a><br/>Synced 6 W&B file(s), 1 media file(s), 129 artifact file(s) and 3 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221002_115622-mvrmqlmt/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# defining some hyperparameters\n",
    "config = {\"epochs\": 10, \"batch_size\": 128, \"lr\": 1e-3, \"dropout\": random.uniform(0.01, 0.80)}\n",
    "\n",
    "# start a wandb run\n",
    "wandb.init(project=\"experiment-tracking\", sync_tensorboard=True, config=config)\n",
    "\n",
    "# we can use config as a dictionary or we can use wandb.config\n",
    "config = wandb.config\n",
    "\n",
    "# Loading train set and validation set\n",
    "train_data = load_data(is_train=True, batch_size=config.batch_size)\n",
    "valid_data = load_data(is_train=False, batch_size=config.batch_size)\n",
    "n_steps_per_epoch = math.ceil(len(train_data.dataset) / config.batch_size)\n",
    "\n",
    "# A multi layer perceptron (MLP) model\n",
    "model = the_model(config.dropout)\n",
    "\n",
    "# Visualizing the neural network (model) using four different methods\n",
    "\n",
    "## 1. Visualizing using TensorBoard\n",
    "tb_writer = SummaryWriter(log_dir=wandb.run.dir)\n",
    "datum = next(iter(train_data))\n",
    "tb_writer.add_graph(model.to(device), datum[0].to(device))\n",
    "\n",
    "## 2. Visualizing using make_dot\n",
    "model.to(device)\n",
    "out = model(datum[0].to(device))\n",
    "model_graph = make_dot(out)\n",
    "pickle.dump(model_graph, open('model_graph.pkl', \"wb\" ))\n",
    "\n",
    "## 3. Saving model layers using wandb.watch command\n",
    "wandb.watch(model, log=\"all\")\n",
    "\n",
    "## 4. Visualizing model using ONNX\n",
    "torch.onnx.export(model,               # model being run\n",
    "                datum[0].to(device),                         # model input (or a tuple for multiple inputs)\n",
    "                \"model.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                export_params=True,        # store the trained parameter weights inside the model file\n",
    "                opset_version=10,          # the ONNX version to export the model to\n",
    "                do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                input_names = ['input'],   # the model's input names\n",
    "                output_names = ['output'], # the model's output names\n",
    "                dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                            'output' : {0 : 'batch_size'}})\n",
    "wandb.save('model.onnx')\n",
    "\n",
    "# Loss function and optimizer\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(config.epochs):\n",
    "    model.train()\n",
    "    for step, (images, labels) in enumerate(train_data):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        train_loss = loss_func(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        metrics = {\"train/train_loss\": train_loss, \"train/epoch\": epoch}\n",
    "        \n",
    "        if step + 1 < n_steps_per_epoch:\n",
    "            # Log metrics to wandb for every batch\n",
    "            wandb.log(metrics)\n",
    "\n",
    "    val_loss, accuracy = validate_model(model, valid_data, loss_func, log_images=(epoch==(config.epochs-1)))\n",
    "    \n",
    "    # Log train and validation metrics to wandb for each epoch\n",
    "    val_metrics = {\"val/val_loss\": val_loss, \"val/val_accuracy\": accuracy}\n",
    "\n",
    "    wandb.log({**metrics, **val_metrics})\n",
    "    \n",
    "    print(f\"Epoch {epoch}. Train Loss: {train_loss:.3f}, Valid Loss: {val_loss:3f}, Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# If you had a test set, this is how you could log it as a Summary metric\n",
    "wandb.summary['test_accuracy'] = 0.8\n",
    "\n",
    "# Saving the learned model after the last epoch\n",
    "torch.save(model.state_dict(), 'model_state.pt')\n",
    "\n",
    "# To save the model state in wandb, you need to use the following command to upload it to your wandb run\n",
    "wandb.save('model_state.pt')\n",
    "\n",
    "# Close your wandb run \n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
